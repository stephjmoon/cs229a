{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "## LOAD DATA\n",
    "fake_all = pd.read_csv(r'C:\\Users\\steph\\Desktop\\CS 229a\\Project\\fake.csv')\n",
    "real_all = pd.read_csv(r'C:\\Users\\steph\\Desktop\\CS 229a\\Project\\real_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLEAN UP DATA: drop examples where the title or text doesn't exist\n",
    "\n",
    "## FAKE NEWS ARTICLES\n",
    "f = {'title': fake_all['title'], 'text': fake_all['text']}\n",
    "fake = pd.DataFrame(f)\n",
    "fake.dropna(inplace=True) # remove none (NA) types in the dt\n",
    "\n",
    "# convert to list\n",
    "fake_title_list = fake['title'].tolist()\n",
    "fake_text_list = fake['text'].tolist()\n",
    "print(len(fake_title_list))\n",
    "print(len(fake_text_list))\n",
    "\n",
    "## REAL NEWS ARTICLES\n",
    "r = {'title': real_all['title'], 'text': real_all['content']}\n",
    "real = pd.DataFrame(r)\n",
    "real.dropna(inplace=True) # remove none (NA) types in the dt\n",
    "\n",
    "# convert to list\n",
    "real_title_list = real['title'].tolist()\n",
    "real_text_list = real['text'].tolist()\n",
    "print(len(real_title_list))\n",
    "print(len(real_text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREPROCESS TEXTS TO USE\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# initialize some variables and tables\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stop_words = set(stopwords.words('english')) \n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all the FAKE TEXTS\n",
    "tokens = []\n",
    "clean_fake_texts = []\n",
    "clean_fake_texts1d = []\n",
    "for i in range(0,len(fake_text_list)):\n",
    "    text = fake_text_list[i]\n",
    "    tokens = tokens + word_tokenize(text) # tokenize\n",
    "    tokens = [w.lower() for w in tokens] # lowercase\n",
    "    stripped = [w.translate(table) for w in tokens] # remove punc\n",
    "    words = [word for word in stripped if word.isalpha()] # remove non-alphabetic\n",
    "    words = [w for w in words if not w in stop_words] # remove stop words\n",
    "    stemmed = [porter.stem(w) for w in words] # stemming of words\n",
    "    clean_fake_texts.append(stemmed)\n",
    "    clean_fake_texts1d = clean_fake_texts1d + stemmed\n",
    "    tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"clean_fake_texts1d.csv\",\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows([clean_fake_texts1d])\n",
    "\n",
    "with open (\"clean_fake_texts.csv\",\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(clean_fake_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all the FAKE TITLES: \n",
    "# clean_fake_titles is a 2D list of all titles, clean_fake_titles1d is the flattened 1D list of all titles\n",
    "tokens = []\n",
    "clean_fake_titles = []\n",
    "clean_fake_titles1d = []\n",
    "for i in range(0,len(fake_title_list)):\n",
    "    title = fake_title_list[i]\n",
    "    tokens = tokens + word_tokenize(title) # tokenize\n",
    "    tokens = [w.lower() for w in tokens] # lowercase\n",
    "    stripped = [w.translate(table) for w in tokens] # remove punc\n",
    "    words = [word for word in stripped if word.isalpha()] # remove non-alphabetic\n",
    "    words = [w for w in words if not w in stop_words] # remove stop words\n",
    "    stemmed = [porter.stem(w) for w in words] # stemming of words\n",
    "    clean_fake_titles.append(stemmed)\n",
    "    clean_fake_titles1d = clean_fake_titles1d + stemmed\n",
    "    tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"clean_fake_titles1d.csv\",\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows([clean_fake_titles1d])\n",
    "\n",
    "with open (\"clean_fake_titles.csv\",\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(clean_fake_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all the REAL TITLES\n",
    "tokens = []\n",
    "clean_real_titles = []\n",
    "clean_real_titles1d = []\n",
    "for i in range(0,len(real_title_list)):\n",
    "    title = real_title_list[i]\n",
    "    tokens = tokens + word_tokenize(title) # tokenize\n",
    "    tokens = [w.lower() for w in tokens] # lowercase\n",
    "    stripped = [w.translate(table) for w in tokens] # remove punc\n",
    "    words = [word for word in stripped if word.isalpha()] # remove non-alphabetic\n",
    "    words = [w for w in words if not w in stop_words] # remove stop words\n",
    "    stemmed = [porter.stem(w) for w in words] # stemming of words\n",
    "    clean_real_titles.append(stemmed)\n",
    "    clean_real_titles1d = clean_real_titles1d + stemmed\n",
    "    tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"clean_real_titles1d.csv\",\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows([clean_real_titles1d])\n",
    "\n",
    "with open (\"clean_real_titles.csv\",\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(clean_real_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all the REAL TEXTS\n",
    "tokens = []\n",
    "clean_real_texts = []\n",
    "clean_real_texts1d = []\n",
    "for i in range(0,len(real_text_list)):\n",
    "    text = real_text_list[i]\n",
    "    tokens = tokens + word_tokenize(text) # tokenize\n",
    "    tokens = [w.lower() for w in tokens] # lowercase\n",
    "    stripped = [w.translate(table) for w in tokens] # remove punc\n",
    "    words = [word for word in stripped if word.isalpha()] # remove non-alphabetic\n",
    "    words = [w for w in words if not w in stop_words] # remove stop words\n",
    "    stemmed = [porter.stem(w) for w in words] # stemming of words\n",
    "    clean_real_texts.append(stemmed)\n",
    "    clean_real_texts1d = clean_real_texts1d + stemmed\n",
    "    tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"clean_real_texts1d.csv\",\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows([clean_real_texts1d])\n",
    "\n",
    "with open (\"clean_real_texts.csv\",\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(clean_real_texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
